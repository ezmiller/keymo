{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/ethan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('brown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, nltk, string\n",
    "from nltk.corpus import brown\n",
    "from nltk.util import ngrams\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "bigrams = list(ngrams(brown.words(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\"),\n",
       " (\"Atlanta's\", 'recent'),\n",
       " ('recent', 'primary'),\n",
       " ('primary', 'election'),\n",
       " ('election', 'produced'),\n",
       " ('produced', '``'),\n",
       " ('``', 'no'),\n",
       " ('no', 'evidence'),\n",
       " ('evidence', \"''\"),\n",
       " (\"''\", 'that'),\n",
       " ('that', 'any')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161191"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bigrams for Certain Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "bigrams_subset = list(ngrams(brown.words(categories=['learned', 'news', 'editorial']), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\"),\n",
       " (\"Atlanta's\", 'recent'),\n",
       " ('recent', 'primary'),\n",
       " ('primary', 'election'),\n",
       " ('election', 'produced'),\n",
       " ('produced', '``'),\n",
       " ('``', 'no'),\n",
       " ('no', 'evidence'),\n",
       " ('evidence', \"''\"),\n",
       " (\"''\", 'that'),\n",
       " ('that', 'any')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_subset[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigrams_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca01',\n",
       " 'ca02',\n",
       " 'ca03',\n",
       " 'ca04',\n",
       " 'ca05',\n",
       " 'ca06',\n",
       " 'ca07',\n",
       " 'ca08',\n",
       " 'ca09',\n",
       " 'ca10',\n",
       " 'ca11',\n",
       " 'ca12',\n",
       " 'ca13',\n",
       " 'ca14',\n",
       " 'ca15',\n",
       " 'ca16',\n",
       " 'ca17',\n",
       " 'ca18',\n",
       " 'ca19',\n",
       " 'ca20',\n",
       " 'ca21',\n",
       " 'ca22',\n",
       " 'ca23',\n",
       " 'ca24',\n",
       " 'ca25',\n",
       " 'ca26',\n",
       " 'ca27',\n",
       " 'ca28',\n",
       " 'ca29',\n",
       " 'ca30',\n",
       " 'ca31',\n",
       " 'ca32',\n",
       " 'ca33',\n",
       " 'ca34',\n",
       " 'ca35',\n",
       " 'ca36',\n",
       " 'ca37',\n",
       " 'ca38',\n",
       " 'ca39',\n",
       " 'ca40',\n",
       " 'ca41',\n",
       " 'ca42',\n",
       " 'ca43',\n",
       " 'ca44',\n",
       " 'cb01',\n",
       " 'cb02',\n",
       " 'cb03',\n",
       " 'cb04',\n",
       " 'cb05',\n",
       " 'cb06',\n",
       " 'cb07',\n",
       " 'cb08',\n",
       " 'cb09',\n",
       " 'cb10',\n",
       " 'cb11',\n",
       " 'cb12',\n",
       " 'cb13',\n",
       " 'cb14',\n",
       " 'cb15',\n",
       " 'cb16',\n",
       " 'cb17',\n",
       " 'cb18',\n",
       " 'cb19',\n",
       " 'cb20',\n",
       " 'cb21',\n",
       " 'cb22',\n",
       " 'cb23',\n",
       " 'cb24',\n",
       " 'cb25',\n",
       " 'cb26',\n",
       " 'cb27',\n",
       " 'cc01',\n",
       " 'cc02',\n",
       " 'cc03',\n",
       " 'cc04',\n",
       " 'cc05',\n",
       " 'cc06',\n",
       " 'cc07',\n",
       " 'cc08',\n",
       " 'cc09',\n",
       " 'cc10',\n",
       " 'cc11',\n",
       " 'cc12',\n",
       " 'cc13',\n",
       " 'cc14',\n",
       " 'cc15',\n",
       " 'cc16',\n",
       " 'cc17',\n",
       " 'cd01',\n",
       " 'cd02',\n",
       " 'cd03',\n",
       " 'cd04',\n",
       " 'cd05',\n",
       " 'cd06',\n",
       " 'cd07',\n",
       " 'cd08',\n",
       " 'cd09',\n",
       " 'cd10',\n",
       " 'cd11',\n",
       " 'cd12',\n",
       " 'cd13',\n",
       " 'cd14',\n",
       " 'cd15',\n",
       " 'cd16',\n",
       " 'cd17',\n",
       " 'ce01',\n",
       " 'ce02',\n",
       " 'ce03',\n",
       " 'ce04',\n",
       " 'ce05',\n",
       " 'ce06',\n",
       " 'ce07',\n",
       " 'ce08',\n",
       " 'ce09',\n",
       " 'ce10',\n",
       " 'ce11',\n",
       " 'ce12',\n",
       " 'ce13',\n",
       " 'ce14',\n",
       " 'ce15',\n",
       " 'ce16',\n",
       " 'ce17',\n",
       " 'ce18',\n",
       " 'ce19',\n",
       " 'ce20',\n",
       " 'ce21',\n",
       " 'ce22',\n",
       " 'ce23',\n",
       " 'ce24',\n",
       " 'ce25',\n",
       " 'ce26',\n",
       " 'ce27',\n",
       " 'ce28',\n",
       " 'ce29',\n",
       " 'ce30',\n",
       " 'ce31',\n",
       " 'ce32',\n",
       " 'ce33',\n",
       " 'ce34',\n",
       " 'ce35',\n",
       " 'ce36',\n",
       " 'cf01',\n",
       " 'cf02',\n",
       " 'cf03',\n",
       " 'cf04',\n",
       " 'cf05',\n",
       " 'cf06',\n",
       " 'cf07',\n",
       " 'cf08',\n",
       " 'cf09',\n",
       " 'cf10',\n",
       " 'cf11',\n",
       " 'cf12',\n",
       " 'cf13',\n",
       " 'cf14',\n",
       " 'cf15',\n",
       " 'cf16',\n",
       " 'cf17',\n",
       " 'cf18',\n",
       " 'cf19',\n",
       " 'cf20',\n",
       " 'cf21',\n",
       " 'cf22',\n",
       " 'cf23',\n",
       " 'cf24',\n",
       " 'cf25',\n",
       " 'cf26',\n",
       " 'cf27',\n",
       " 'cf28',\n",
       " 'cf29',\n",
       " 'cf30',\n",
       " 'cf31',\n",
       " 'cf32',\n",
       " 'cf33',\n",
       " 'cf34',\n",
       " 'cf35',\n",
       " 'cf36',\n",
       " 'cf37',\n",
       " 'cf38',\n",
       " 'cf39',\n",
       " 'cf40',\n",
       " 'cf41',\n",
       " 'cf42',\n",
       " 'cf43',\n",
       " 'cf44',\n",
       " 'cf45',\n",
       " 'cf46',\n",
       " 'cf47',\n",
       " 'cf48',\n",
       " 'cg01',\n",
       " 'cg02',\n",
       " 'cg03',\n",
       " 'cg04',\n",
       " 'cg05',\n",
       " 'cg06',\n",
       " 'cg07',\n",
       " 'cg08',\n",
       " 'cg09',\n",
       " 'cg10',\n",
       " 'cg11',\n",
       " 'cg12',\n",
       " 'cg13',\n",
       " 'cg14',\n",
       " 'cg15',\n",
       " 'cg16',\n",
       " 'cg17',\n",
       " 'cg18',\n",
       " 'cg19',\n",
       " 'cg20',\n",
       " 'cg21',\n",
       " 'cg22',\n",
       " 'cg23',\n",
       " 'cg24',\n",
       " 'cg25',\n",
       " 'cg26',\n",
       " 'cg27',\n",
       " 'cg28',\n",
       " 'cg29',\n",
       " 'cg30',\n",
       " 'cg31',\n",
       " 'cg32',\n",
       " 'cg33',\n",
       " 'cg34',\n",
       " 'cg35',\n",
       " 'cg36',\n",
       " 'cg37',\n",
       " 'cg38',\n",
       " 'cg39',\n",
       " 'cg40',\n",
       " 'cg41',\n",
       " 'cg42',\n",
       " 'cg43',\n",
       " 'cg44',\n",
       " 'cg45',\n",
       " 'cg46',\n",
       " 'cg47',\n",
       " 'cg48',\n",
       " 'cg49',\n",
       " 'cg50',\n",
       " 'cg51',\n",
       " 'cg52',\n",
       " 'cg53',\n",
       " 'cg54',\n",
       " 'cg55',\n",
       " 'cg56',\n",
       " 'cg57',\n",
       " 'cg58',\n",
       " 'cg59',\n",
       " 'cg60',\n",
       " 'cg61',\n",
       " 'cg62',\n",
       " 'cg63',\n",
       " 'cg64',\n",
       " 'cg65',\n",
       " 'cg66',\n",
       " 'cg67',\n",
       " 'cg68',\n",
       " 'cg69',\n",
       " 'cg70',\n",
       " 'cg71',\n",
       " 'cg72',\n",
       " 'cg73',\n",
       " 'cg74',\n",
       " 'cg75',\n",
       " 'ch01',\n",
       " 'ch02',\n",
       " 'ch03',\n",
       " 'ch04',\n",
       " 'ch05',\n",
       " 'ch06',\n",
       " 'ch07',\n",
       " 'ch08',\n",
       " 'ch09',\n",
       " 'ch10',\n",
       " 'ch11',\n",
       " 'ch12',\n",
       " 'ch13',\n",
       " 'ch14',\n",
       " 'ch15',\n",
       " 'ch16',\n",
       " 'ch17',\n",
       " 'ch18',\n",
       " 'ch19',\n",
       " 'ch20',\n",
       " 'ch21',\n",
       " 'ch22',\n",
       " 'ch23',\n",
       " 'ch24',\n",
       " 'ch25',\n",
       " 'ch26',\n",
       " 'ch27',\n",
       " 'ch28',\n",
       " 'ch29',\n",
       " 'ch30',\n",
       " 'cj01',\n",
       " 'cj02',\n",
       " 'cj03',\n",
       " 'cj04',\n",
       " 'cj05',\n",
       " 'cj06',\n",
       " 'cj07',\n",
       " 'cj08',\n",
       " 'cj09',\n",
       " 'cj10',\n",
       " 'cj11',\n",
       " 'cj12',\n",
       " 'cj13',\n",
       " 'cj14',\n",
       " 'cj15',\n",
       " 'cj16',\n",
       " 'cj17',\n",
       " 'cj18',\n",
       " 'cj19',\n",
       " 'cj20',\n",
       " 'cj21',\n",
       " 'cj22',\n",
       " 'cj23',\n",
       " 'cj24',\n",
       " 'cj25',\n",
       " 'cj26',\n",
       " 'cj27',\n",
       " 'cj28',\n",
       " 'cj29',\n",
       " 'cj30',\n",
       " 'cj31',\n",
       " 'cj32',\n",
       " 'cj33',\n",
       " 'cj34',\n",
       " 'cj35',\n",
       " 'cj36',\n",
       " 'cj37',\n",
       " 'cj38',\n",
       " 'cj39',\n",
       " 'cj40',\n",
       " 'cj41',\n",
       " 'cj42',\n",
       " 'cj43',\n",
       " 'cj44',\n",
       " 'cj45',\n",
       " 'cj46',\n",
       " 'cj47',\n",
       " 'cj48',\n",
       " 'cj49',\n",
       " 'cj50',\n",
       " 'cj51',\n",
       " 'cj52',\n",
       " 'cj53',\n",
       " 'cj54',\n",
       " 'cj55',\n",
       " 'cj56',\n",
       " 'cj57',\n",
       " 'cj58',\n",
       " 'cj59',\n",
       " 'cj60',\n",
       " 'cj61',\n",
       " 'cj62',\n",
       " 'cj63',\n",
       " 'cj64',\n",
       " 'cj65',\n",
       " 'cj66',\n",
       " 'cj67',\n",
       " 'cj68',\n",
       " 'cj69',\n",
       " 'cj70',\n",
       " 'cj71',\n",
       " 'cj72',\n",
       " 'cj73',\n",
       " 'cj74',\n",
       " 'cj75',\n",
       " 'cj76',\n",
       " 'cj77',\n",
       " 'cj78',\n",
       " 'cj79',\n",
       " 'cj80',\n",
       " 'ck01',\n",
       " 'ck02',\n",
       " 'ck03',\n",
       " 'ck04',\n",
       " 'ck05',\n",
       " 'ck06',\n",
       " 'ck07',\n",
       " 'ck08',\n",
       " 'ck09',\n",
       " 'ck10',\n",
       " 'ck11',\n",
       " 'ck12',\n",
       " 'ck13',\n",
       " 'ck14',\n",
       " 'ck15',\n",
       " 'ck16',\n",
       " 'ck17',\n",
       " 'ck18',\n",
       " 'ck19',\n",
       " 'ck20',\n",
       " 'ck21',\n",
       " 'ck22',\n",
       " 'ck23',\n",
       " 'ck24',\n",
       " 'ck25',\n",
       " 'ck26',\n",
       " 'ck27',\n",
       " 'ck28',\n",
       " 'ck29',\n",
       " 'cl01',\n",
       " 'cl02',\n",
       " 'cl03',\n",
       " 'cl04',\n",
       " 'cl05',\n",
       " 'cl06',\n",
       " 'cl07',\n",
       " 'cl08',\n",
       " 'cl09',\n",
       " 'cl10',\n",
       " 'cl11',\n",
       " 'cl12',\n",
       " 'cl13',\n",
       " 'cl14',\n",
       " 'cl15',\n",
       " 'cl16',\n",
       " 'cl17',\n",
       " 'cl18',\n",
       " 'cl19',\n",
       " 'cl20',\n",
       " 'cl21',\n",
       " 'cl22',\n",
       " 'cl23',\n",
       " 'cl24',\n",
       " 'cm01',\n",
       " 'cm02',\n",
       " 'cm03',\n",
       " 'cm04',\n",
       " 'cm05',\n",
       " 'cm06',\n",
       " 'cn01',\n",
       " 'cn02',\n",
       " 'cn03',\n",
       " 'cn04',\n",
       " 'cn05',\n",
       " 'cn06',\n",
       " 'cn07',\n",
       " 'cn08',\n",
       " 'cn09',\n",
       " 'cn10',\n",
       " 'cn11',\n",
       " 'cn12',\n",
       " 'cn13',\n",
       " 'cn14',\n",
       " 'cn15',\n",
       " 'cn16',\n",
       " 'cn17',\n",
       " 'cn18',\n",
       " 'cn19',\n",
       " 'cn20',\n",
       " 'cn21',\n",
       " 'cn22',\n",
       " 'cn23',\n",
       " 'cn24',\n",
       " 'cn25',\n",
       " 'cn26',\n",
       " 'cn27',\n",
       " 'cn28',\n",
       " 'cn29',\n",
       " 'cp01',\n",
       " 'cp02',\n",
       " 'cp03',\n",
       " 'cp04',\n",
       " 'cp05',\n",
       " 'cp06',\n",
       " 'cp07',\n",
       " 'cp08',\n",
       " 'cp09',\n",
       " 'cp10',\n",
       " 'cp11',\n",
       " 'cp12',\n",
       " 'cp13',\n",
       " 'cp14',\n",
       " 'cp15',\n",
       " 'cp16',\n",
       " 'cp17',\n",
       " 'cp18',\n",
       " 'cp19',\n",
       " 'cp20',\n",
       " 'cp21',\n",
       " 'cp22',\n",
       " 'cp23',\n",
       " 'cp24',\n",
       " 'cp25',\n",
       " 'cp26',\n",
       " 'cp27',\n",
       " 'cp28',\n",
       " 'cp29',\n",
       " 'cr01',\n",
       " 'cr02',\n",
       " 'cr03',\n",
       " 'cr04',\n",
       " 'cr05',\n",
       " 'cr06',\n",
       " 'cr07',\n",
       " 'cr08',\n",
       " 'cr09']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.fileids() # ids for individual docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place . The jury further said in\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(brown.words('ca01')[:30]) # join words for a given doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_docs = [brown.words(file_id) for file_id in brown.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...],\n",
       " ['Austin', ',', 'Texas', '--', 'Committee', 'approval', ...]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_docs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-15 17:12:54,039 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-06-15 17:12:54,159 : INFO : adding document #10000 to Dictionary(2690 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,251 : INFO : adding document #20000 to Dictionary(4362 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,342 : INFO : adding document #30000 to Dictionary(6004 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,429 : INFO : adding document #40000 to Dictionary(7624 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,524 : INFO : adding document #50000 to Dictionary(8920 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,607 : INFO : adding document #60000 to Dictionary(10177 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,693 : INFO : adding document #70000 to Dictionary(11546 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,772 : INFO : adding document #80000 to Dictionary(12547 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,853 : INFO : adding document #90000 to Dictionary(13524 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:54,932 : INFO : adding document #100000 to Dictionary(14362 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,010 : INFO : adding document #110000 to Dictionary(15174 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,102 : INFO : adding document #120000 to Dictionary(15839 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,181 : INFO : adding document #130000 to Dictionary(16701 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,261 : INFO : adding document #140000 to Dictionary(17266 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,344 : INFO : adding document #150000 to Dictionary(17955 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,432 : INFO : adding document #160000 to Dictionary(18778 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,517 : INFO : adding document #170000 to Dictionary(19660 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,601 : INFO : adding document #180000 to Dictionary(20634 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,692 : INFO : adding document #190000 to Dictionary(21467 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,780 : INFO : adding document #200000 to Dictionary(22365 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,858 : INFO : adding document #210000 to Dictionary(23004 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:55,942 : INFO : adding document #220000 to Dictionary(23497 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,014 : INFO : adding document #230000 to Dictionary(23962 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,099 : INFO : adding document #240000 to Dictionary(24425 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,180 : INFO : adding document #250000 to Dictionary(24997 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,257 : INFO : adding document #260000 to Dictionary(25523 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,343 : INFO : adding document #270000 to Dictionary(26503 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,421 : INFO : adding document #280000 to Dictionary(27176 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,503 : INFO : adding document #290000 to Dictionary(27699 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,593 : INFO : adding document #300000 to Dictionary(28238 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,677 : INFO : adding document #310000 to Dictionary(28701 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,754 : INFO : adding document #320000 to Dictionary(29139 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,832 : INFO : adding document #330000 to Dictionary(29693 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:56,911 : INFO : adding document #340000 to Dictionary(30201 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,001 : INFO : adding document #350000 to Dictionary(30651 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,080 : INFO : adding document #360000 to Dictionary(30994 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,160 : INFO : adding document #370000 to Dictionary(31636 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,239 : INFO : adding document #380000 to Dictionary(32097 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,320 : INFO : adding document #390000 to Dictionary(32584 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,410 : INFO : adding document #400000 to Dictionary(32961 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,492 : INFO : adding document #410000 to Dictionary(33514 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,573 : INFO : adding document #420000 to Dictionary(33964 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,661 : INFO : adding document #430000 to Dictionary(34335 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,739 : INFO : adding document #440000 to Dictionary(34634 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,822 : INFO : adding document #450000 to Dictionary(35097 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,899 : INFO : adding document #460000 to Dictionary(35484 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:57,978 : INFO : adding document #470000 to Dictionary(35964 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,060 : INFO : adding document #480000 to Dictionary(36363 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,141 : INFO : adding document #490000 to Dictionary(36658 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,217 : INFO : adding document #500000 to Dictionary(37013 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,294 : INFO : adding document #510000 to Dictionary(37376 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,375 : INFO : adding document #520000 to Dictionary(37684 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,458 : INFO : adding document #530000 to Dictionary(38069 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,556 : INFO : adding document #540000 to Dictionary(38349 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,639 : INFO : adding document #550000 to Dictionary(38754 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,719 : INFO : adding document #560000 to Dictionary(39105 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,807 : INFO : adding document #570000 to Dictionary(39412 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:58,890 : INFO : adding document #580000 to Dictionary(39844 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-15 17:12:58,972 : INFO : adding document #590000 to Dictionary(40411 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,052 : INFO : adding document #600000 to Dictionary(40744 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,137 : INFO : adding document #610000 to Dictionary(41078 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,223 : INFO : adding document #620000 to Dictionary(41266 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,303 : INFO : adding document #630000 to Dictionary(41484 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,379 : INFO : adding document #640000 to Dictionary(41792 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,462 : INFO : adding document #650000 to Dictionary(41991 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,537 : INFO : adding document #660000 to Dictionary(42184 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,618 : INFO : adding document #670000 to Dictionary(42404 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,695 : INFO : adding document #680000 to Dictionary(42694 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,776 : INFO : adding document #690000 to Dictionary(43113 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,865 : INFO : adding document #700000 to Dictionary(43545 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:12:59,955 : INFO : adding document #710000 to Dictionary(43955 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,037 : INFO : adding document #720000 to Dictionary(44412 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,141 : INFO : adding document #730000 to Dictionary(44593 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,228 : INFO : adding document #740000 to Dictionary(44856 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,308 : INFO : adding document #750000 to Dictionary(45105 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,395 : INFO : adding document #760000 to Dictionary(45429 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,475 : INFO : adding document #770000 to Dictionary(45614 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,569 : INFO : adding document #780000 to Dictionary(45817 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,671 : INFO : adding document #790000 to Dictionary(45981 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,758 : INFO : adding document #800000 to Dictionary(46187 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,846 : INFO : adding document #810000 to Dictionary(46497 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:00,931 : INFO : adding document #820000 to Dictionary(46731 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,013 : INFO : adding document #830000 to Dictionary(47105 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,120 : INFO : adding document #840000 to Dictionary(47527 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,202 : INFO : adding document #850000 to Dictionary(47928 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,281 : INFO : adding document #860000 to Dictionary(48224 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,361 : INFO : adding document #870000 to Dictionary(48476 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,443 : INFO : adding document #880000 to Dictionary(48816 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,520 : INFO : adding document #890000 to Dictionary(49189 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,603 : INFO : adding document #900000 to Dictionary(49553 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,693 : INFO : adding document #910000 to Dictionary(49862 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,775 : INFO : adding document #920000 to Dictionary(50116 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,862 : INFO : adding document #930000 to Dictionary(50364 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:01,939 : INFO : adding document #940000 to Dictionary(50589 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,023 : INFO : adding document #950000 to Dictionary(50796 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,100 : INFO : adding document #960000 to Dictionary(51002 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,185 : INFO : adding document #970000 to Dictionary(51244 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,282 : INFO : adding document #980000 to Dictionary(51471 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,374 : INFO : adding document #990000 to Dictionary(51716 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,455 : INFO : adding document #1000000 to Dictionary(51975 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,558 : INFO : adding document #1010000 to Dictionary(52148 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,638 : INFO : adding document #1020000 to Dictionary(52355 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,721 : INFO : adding document #1030000 to Dictionary(52634 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,810 : INFO : adding document #1040000 to Dictionary(53026 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,893 : INFO : adding document #1050000 to Dictionary(53284 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:02,975 : INFO : adding document #1060000 to Dictionary(53521 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,070 : INFO : adding document #1070000 to Dictionary(53845 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,154 : INFO : adding document #1080000 to Dictionary(54136 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,245 : INFO : adding document #1090000 to Dictionary(54353 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,327 : INFO : adding document #1100000 to Dictionary(54537 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,421 : INFO : adding document #1110000 to Dictionary(54765 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,499 : INFO : adding document #1120000 to Dictionary(54936 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,574 : INFO : adding document #1130000 to Dictionary(55114 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,655 : INFO : adding document #1140000 to Dictionary(55297 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,740 : INFO : adding document #1150000 to Dictionary(55578 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n",
      "2018-06-15 17:13:03,822 : INFO : adding document #1160000 to Dictionary(55983 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-15 17:13:03,833 : INFO : built Dictionary(56057 unique tokens: ['Fulton', 'The', 'County', 'Grand', 'Jury']...) from 1161191 documents (total 2322382 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dict = gensim.corpora.Dictionary(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 s, sys: 474 ms, total: 8.48 s\n",
      "Wall time: 8.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def tokenize(text):\n",
    "    punct = set(string.punctuation)\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    unigrams = [\" \".join(token) for token in list(ngrams(text, 1))]\n",
    "    bigrams = [\" \".join(token) for token in list (ngrams(text, 2))]\n",
    "    tokens = [token for token in (unigrams + bigrams)\n",
    "              if token not in stopwords\n",
    "              and token not in punct]\n",
    "    return tokens\n",
    "\n",
    "brown_docs_tokenized = [tokenize(text) for text in brown_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'investigation',\n",
       " \"Atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " 'The',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'term-end',\n",
       " 'presentments',\n",
       " 'City',\n",
       " 'Executive',\n",
       " 'Committee',\n",
       " 'over-all',\n",
       " 'charge',\n",
       " 'election',\n",
       " '``',\n",
       " 'deserves',\n",
       " 'praise',\n",
       " 'thanks',\n",
       " 'City',\n",
       " 'Atlanta',\n",
       " \"''\",\n",
       " 'manner',\n",
       " 'election',\n",
       " 'conducted',\n",
       " 'The',\n",
       " 'September-October',\n",
       " 'term',\n",
       " 'jury',\n",
       " 'charged',\n",
       " 'Fulton',\n",
       " 'Superior',\n",
       " 'Court',\n",
       " 'Judge',\n",
       " 'Durwood',\n",
       " 'Pye',\n",
       " 'investigate',\n",
       " 'reports',\n",
       " 'possible',\n",
       " '``',\n",
       " 'irregularities',\n",
       " \"''\",\n",
       " 'hard-fought',\n",
       " 'primary',\n",
       " 'Mayor-nominate',\n",
       " 'Ivan',\n",
       " 'Allen',\n",
       " 'Jr.',\n",
       " '``',\n",
       " 'Only',\n",
       " 'relative',\n",
       " 'handful',\n",
       " 'reports',\n",
       " 'received',\n",
       " \"''\",\n",
       " 'jury',\n",
       " 'said',\n",
       " '``',\n",
       " 'considering',\n",
       " 'widespread',\n",
       " 'interest',\n",
       " 'election',\n",
       " 'number',\n",
       " 'voters',\n",
       " 'size',\n",
       " 'city',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'find',\n",
       " 'many',\n",
       " \"Georgia's\",\n",
       " 'registration',\n",
       " 'election',\n",
       " 'laws',\n",
       " '``',\n",
       " 'outmoded',\n",
       " 'inadequate',\n",
       " 'often',\n",
       " 'ambiguous',\n",
       " \"''\",\n",
       " 'It',\n",
       " 'recommended',\n",
       " 'Fulton',\n",
       " 'legislators',\n",
       " 'act',\n",
       " '``',\n",
       " 'laws',\n",
       " 'studied',\n",
       " 'revised',\n",
       " 'end',\n",
       " 'modernizing',\n",
       " 'improving',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'commented',\n",
       " 'number',\n",
       " 'topics',\n",
       " 'among',\n",
       " 'Atlanta',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'purchasing',\n",
       " 'departments',\n",
       " 'said',\n",
       " '``',\n",
       " 'well',\n",
       " 'operated',\n",
       " 'follow',\n",
       " 'generally',\n",
       " 'accepted',\n",
       " 'practices',\n",
       " 'inure',\n",
       " 'best',\n",
       " 'interest',\n",
       " 'governments',\n",
       " \"''\",\n",
       " 'Merger',\n",
       " 'proposed',\n",
       " 'However',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'believes',\n",
       " '``',\n",
       " 'two',\n",
       " 'offices',\n",
       " 'combined',\n",
       " 'achieve',\n",
       " 'greater',\n",
       " 'efficiency',\n",
       " 'reduce',\n",
       " 'cost',\n",
       " 'administration',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'City',\n",
       " 'Purchasing',\n",
       " 'Department',\n",
       " 'jury',\n",
       " 'said',\n",
       " '``',\n",
       " 'lacking',\n",
       " 'experienced',\n",
       " 'clerical',\n",
       " 'personnel',\n",
       " 'result',\n",
       " 'city',\n",
       " 'personnel',\n",
       " 'policies',\n",
       " \"''\",\n",
       " 'It',\n",
       " 'urged',\n",
       " 'city',\n",
       " '``',\n",
       " 'take',\n",
       " 'steps',\n",
       " 'remedy',\n",
       " \"''\",\n",
       " 'problem',\n",
       " 'Implementation',\n",
       " \"Georgia's\",\n",
       " 'automobile',\n",
       " 'title',\n",
       " 'law',\n",
       " 'also',\n",
       " 'recommended',\n",
       " 'outgoing',\n",
       " 'jury',\n",
       " 'It',\n",
       " 'urged',\n",
       " 'next',\n",
       " 'Legislature',\n",
       " '``',\n",
       " 'provide',\n",
       " 'enabling',\n",
       " 'funds',\n",
       " 're-set',\n",
       " 'effective',\n",
       " 'date',\n",
       " 'orderly',\n",
       " 'implementation',\n",
       " 'law',\n",
       " 'may',\n",
       " 'effected',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'took',\n",
       " 'swipe',\n",
       " 'State',\n",
       " 'Welfare',\n",
       " \"Department's\",\n",
       " 'handling',\n",
       " 'federal',\n",
       " 'funds',\n",
       " 'granted',\n",
       " 'child',\n",
       " 'welfare',\n",
       " 'services',\n",
       " 'foster',\n",
       " 'homes',\n",
       " '``',\n",
       " 'This',\n",
       " 'one',\n",
       " 'major',\n",
       " 'items',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'general',\n",
       " 'assistance',\n",
       " 'program',\n",
       " \"''\",\n",
       " 'jury',\n",
       " 'said',\n",
       " 'State',\n",
       " 'Welfare',\n",
       " 'Department',\n",
       " '``',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'distribute',\n",
       " 'funds',\n",
       " 'welfare',\n",
       " 'departments',\n",
       " 'counties',\n",
       " 'state',\n",
       " 'exception',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'receives',\n",
       " 'none',\n",
       " 'money',\n",
       " 'The',\n",
       " 'jurors',\n",
       " 'said',\n",
       " 'realize',\n",
       " '``',\n",
       " 'proportionate',\n",
       " 'distribution',\n",
       " 'funds',\n",
       " 'might',\n",
       " 'disable',\n",
       " 'program',\n",
       " 'less',\n",
       " 'populous',\n",
       " 'counties',\n",
       " \"''\",\n",
       " 'Nevertheless',\n",
       " '``',\n",
       " 'feel',\n",
       " 'future',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'receive',\n",
       " 'portion',\n",
       " 'available',\n",
       " 'funds',\n",
       " \"''\",\n",
       " 'jurors',\n",
       " 'said',\n",
       " '``',\n",
       " 'Failure',\n",
       " 'continue',\n",
       " 'place',\n",
       " 'disproportionate',\n",
       " 'burden',\n",
       " \"''\",\n",
       " 'Fulton',\n",
       " 'taxpayers',\n",
       " 'The',\n",
       " 'jury',\n",
       " 'also',\n",
       " 'commented',\n",
       " 'Fulton',\n",
       " \"ordinary's\",\n",
       " 'court',\n",
       " 'fire',\n",
       " 'practices',\n",
       " 'appointment',\n",
       " 'appraisers',\n",
       " 'guardians',\n",
       " 'administrators',\n",
       " 'awarding',\n",
       " 'fees',\n",
       " 'compensation',\n",
       " 'Wards',\n",
       " 'protected',\n",
       " 'The',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'found',\n",
       " 'court',\n",
       " '``',\n",
       " 'incorporated',\n",
       " 'operating',\n",
       " 'procedures',\n",
       " 'recommendations',\n",
       " \"''\",\n",
       " 'two',\n",
       " 'previous',\n",
       " 'grand',\n",
       " 'juries',\n",
       " 'Atlanta',\n",
       " 'Bar',\n",
       " 'Association',\n",
       " 'interim',\n",
       " 'citizens',\n",
       " 'committee',\n",
       " '``',\n",
       " 'These',\n",
       " 'actions',\n",
       " 'serve',\n",
       " 'protect',\n",
       " 'fact',\n",
       " 'effect',\n",
       " \"court's\",\n",
       " 'wards',\n",
       " 'undue',\n",
       " 'costs',\n",
       " 'appointed',\n",
       " 'elected',\n",
       " 'servants',\n",
       " 'unmeritorious',\n",
       " 'criticisms',\n",
       " \"''\",\n",
       " 'jury',\n",
       " 'said',\n",
       " 'Regarding',\n",
       " \"Atlanta's\",\n",
       " 'new',\n",
       " 'multi-million-dollar',\n",
       " 'airport',\n",
       " 'jury',\n",
       " 'recommended',\n",
       " '``',\n",
       " 'new',\n",
       " 'management',\n",
       " 'takes',\n",
       " 'charge',\n",
       " 'Jan.',\n",
       " '1',\n",
       " 'airport',\n",
       " 'operated',\n",
       " 'manner',\n",
       " 'eliminate',\n",
       " 'political',\n",
       " 'influences',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'jury',\n",
       " 'elaborate',\n",
       " 'added',\n",
       " '``',\n",
       " 'periodic',\n",
       " 'surveillance',\n",
       " 'pricing',\n",
       " 'practices',\n",
       " 'concessionaires',\n",
       " 'purpose',\n",
       " 'keeping',\n",
       " 'prices',\n",
       " 'reasonable',\n",
       " \"''\",\n",
       " 'Ask',\n",
       " 'jail',\n",
       " 'deputies',\n",
       " 'On',\n",
       " 'matters',\n",
       " 'jury',\n",
       " 'recommended',\n",
       " '1',\n",
       " 'Four',\n",
       " 'additional',\n",
       " 'deputies',\n",
       " 'employed',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Jail',\n",
       " '``',\n",
       " 'doctor',\n",
       " 'medical',\n",
       " 'intern',\n",
       " 'extern',\n",
       " 'employed',\n",
       " 'night',\n",
       " 'weekend',\n",
       " 'duty',\n",
       " 'jail',\n",
       " \"''\",\n",
       " '2',\n",
       " 'Fulton',\n",
       " 'legislators',\n",
       " '``',\n",
       " 'work',\n",
       " 'city',\n",
       " 'officials',\n",
       " 'pass',\n",
       " 'enabling',\n",
       " 'legislation',\n",
       " 'permit',\n",
       " 'establishment',\n",
       " 'fair',\n",
       " 'equitable',\n",
       " \"''\",\n",
       " 'pension',\n",
       " 'plan',\n",
       " 'city',\n",
       " 'employes',\n",
       " 'The',\n",
       " 'jury',\n",
       " 'praised',\n",
       " 'administration',\n",
       " 'operation',\n",
       " 'Atlanta',\n",
       " 'Police',\n",
       " 'Department',\n",
       " 'Fulton',\n",
       " 'Tax',\n",
       " \"Commissioner's\",\n",
       " 'Office',\n",
       " 'Bellwood',\n",
       " 'Alpharetta',\n",
       " 'prison',\n",
       " 'farms',\n",
       " 'Grady',\n",
       " 'Hospital',\n",
       " 'Fulton',\n",
       " 'Health',\n",
       " 'Department',\n",
       " 'Mayor',\n",
       " 'William',\n",
       " 'B.',\n",
       " 'Hartsfield',\n",
       " 'filed',\n",
       " 'suit',\n",
       " 'divorce',\n",
       " 'wife',\n",
       " 'Pearl',\n",
       " 'Williams',\n",
       " 'Hartsfield',\n",
       " 'Fulton',\n",
       " 'Superior',\n",
       " 'Court',\n",
       " 'Friday',\n",
       " 'His',\n",
       " 'petition',\n",
       " 'charged',\n",
       " 'mental',\n",
       " 'cruelty',\n",
       " 'The',\n",
       " 'couple',\n",
       " 'married',\n",
       " 'Aug.',\n",
       " '2',\n",
       " '1913',\n",
       " 'They',\n",
       " 'son',\n",
       " 'William',\n",
       " 'Berry',\n",
       " 'Jr.',\n",
       " 'daughter',\n",
       " 'Mrs.',\n",
       " 'J.',\n",
       " 'M.',\n",
       " 'Cheshire',\n",
       " 'Griffin',\n",
       " 'Attorneys',\n",
       " 'mayor',\n",
       " 'said',\n",
       " 'amicable',\n",
       " 'property',\n",
       " 'settlement',\n",
       " 'agreed',\n",
       " 'upon',\n",
       " 'The',\n",
       " 'petition',\n",
       " 'listed',\n",
       " \"mayor's\",\n",
       " 'occupation',\n",
       " '``',\n",
       " 'attorney',\n",
       " \"''\",\n",
       " 'age',\n",
       " '71',\n",
       " 'It',\n",
       " 'listed',\n",
       " \"wife's\",\n",
       " 'age',\n",
       " '74',\n",
       " 'place',\n",
       " 'birth',\n",
       " 'Opelika',\n",
       " 'Ala.',\n",
       " 'The',\n",
       " 'petition',\n",
       " 'said',\n",
       " 'couple',\n",
       " 'lived',\n",
       " 'together',\n",
       " 'man',\n",
       " 'wife',\n",
       " 'year',\n",
       " 'The',\n",
       " 'Hartsfield',\n",
       " 'home',\n",
       " '637',\n",
       " 'E.',\n",
       " 'Pelham',\n",
       " 'Rd.',\n",
       " 'Aj',\n",
       " 'Henry',\n",
       " 'L.',\n",
       " 'Bowden',\n",
       " 'listed',\n",
       " 'petition',\n",
       " \"mayor's\",\n",
       " 'attorney',\n",
       " 'Hartsfield',\n",
       " 'mayor',\n",
       " 'Atlanta',\n",
       " 'exception',\n",
       " 'one',\n",
       " 'brief',\n",
       " 'interlude',\n",
       " 'since',\n",
       " '1937',\n",
       " 'His',\n",
       " 'political',\n",
       " 'career',\n",
       " 'goes',\n",
       " 'back',\n",
       " 'election',\n",
       " 'city',\n",
       " 'council',\n",
       " '1923',\n",
       " 'The',\n",
       " \"mayor's\",\n",
       " 'present',\n",
       " 'term',\n",
       " 'office',\n",
       " 'expires',\n",
       " 'Jan.',\n",
       " '1',\n",
       " 'He',\n",
       " 'succeeded',\n",
       " 'Ivan',\n",
       " 'Allen',\n",
       " 'Jr.',\n",
       " 'became',\n",
       " 'candidate',\n",
       " 'Sept.',\n",
       " '13',\n",
       " 'primary',\n",
       " 'Mayor',\n",
       " 'Hartsfield',\n",
       " 'announced',\n",
       " 'would',\n",
       " 'run',\n",
       " 'reelection',\n",
       " 'Georgia',\n",
       " 'Republicans',\n",
       " 'getting',\n",
       " 'strong',\n",
       " 'encouragement',\n",
       " 'enter',\n",
       " 'candidate',\n",
       " '1962',\n",
       " \"governor's\",\n",
       " 'race',\n",
       " 'top',\n",
       " 'official',\n",
       " 'said',\n",
       " 'Wednesday',\n",
       " 'Robert',\n",
       " 'Snodgrass',\n",
       " 'state',\n",
       " 'GOP',\n",
       " 'chairman',\n",
       " 'said',\n",
       " 'meeting',\n",
       " 'held',\n",
       " 'Tuesday',\n",
       " 'night',\n",
       " 'Blue',\n",
       " 'Ridge',\n",
       " 'brought',\n",
       " 'enthusiastic',\n",
       " 'responses',\n",
       " 'audience',\n",
       " 'State',\n",
       " 'Party',\n",
       " 'Chairman',\n",
       " 'James',\n",
       " 'W.',\n",
       " 'Dorsey',\n",
       " 'added',\n",
       " 'enthusiasm',\n",
       " 'picking',\n",
       " 'state',\n",
       " 'rally',\n",
       " 'held',\n",
       " 'Sept.',\n",
       " '8',\n",
       " 'Savannah',\n",
       " 'newly',\n",
       " 'elected',\n",
       " 'Texas',\n",
       " 'Sen.',\n",
       " 'John',\n",
       " 'Tower',\n",
       " 'featured',\n",
       " 'speaker',\n",
       " 'In',\n",
       " 'Blue',\n",
       " 'Ridge',\n",
       " 'meeting',\n",
       " 'audience',\n",
       " 'warned',\n",
       " 'entering',\n",
       " 'candidate',\n",
       " 'governor',\n",
       " 'would',\n",
       " 'force',\n",
       " 'take',\n",
       " 'petitions',\n",
       " 'voting',\n",
       " 'precincts',\n",
       " 'obtain',\n",
       " 'signatures',\n",
       " 'registered',\n",
       " 'voters',\n",
       " 'Despite',\n",
       " 'warning',\n",
       " 'unanimous',\n",
       " 'vote',\n",
       " 'enter',\n",
       " 'candidate',\n",
       " 'according',\n",
       " 'Republicans',\n",
       " 'attended',\n",
       " 'When',\n",
       " 'crowd',\n",
       " 'asked',\n",
       " 'whether',\n",
       " 'wanted',\n",
       " 'wait',\n",
       " 'one',\n",
       " 'term',\n",
       " 'make',\n",
       " 'race',\n",
       " 'voted',\n",
       " '--',\n",
       " 'dissents',\n",
       " 'The',\n",
       " 'largest',\n",
       " 'hurdle',\n",
       " 'Republicans',\n",
       " 'would',\n",
       " 'face',\n",
       " 'state',\n",
       " 'law',\n",
       " 'says',\n",
       " 'making',\n",
       " 'first',\n",
       " 'race',\n",
       " 'one',\n",
       " 'two',\n",
       " 'alternative',\n",
       " 'courses',\n",
       " 'must',\n",
       " 'taken',\n",
       " '1',\n",
       " 'Five',\n",
       " 'per',\n",
       " 'cent',\n",
       " 'voters',\n",
       " 'county',\n",
       " 'must',\n",
       " 'sign',\n",
       " 'petitions',\n",
       " 'requesting',\n",
       " 'Republicans',\n",
       " 'allowed',\n",
       " 'place',\n",
       " 'names',\n",
       " 'candidates',\n",
       " 'general',\n",
       " 'election',\n",
       " 'ballot',\n",
       " '2',\n",
       " 'The',\n",
       " 'Republicans',\n",
       " 'must',\n",
       " 'hold',\n",
       " 'primary',\n",
       " 'county',\n",
       " 'unit',\n",
       " 'system',\n",
       " '--',\n",
       " 'system',\n",
       " 'party',\n",
       " 'opposes',\n",
       " 'platform',\n",
       " 'Sam',\n",
       " 'Caldwell',\n",
       " 'State',\n",
       " 'Highway',\n",
       " 'Department',\n",
       " 'public',\n",
       " 'relations',\n",
       " 'director',\n",
       " 'resigned',\n",
       " 'Tuesday',\n",
       " 'work',\n",
       " 'Lt.',\n",
       " 'Gov.',\n",
       " 'Garland',\n",
       " \"Byrd's\",\n",
       " 'campaign',\n",
       " \"Caldwell's\",\n",
       " 'resignation',\n",
       " 'expected',\n",
       " 'time',\n",
       " 'He',\n",
       " 'succeeded',\n",
       " 'Rob',\n",
       " 'Ledford',\n",
       " 'Gainesville',\n",
       " 'assistant',\n",
       " 'three',\n",
       " 'years',\n",
       " 'When',\n",
       " 'gubernatorial',\n",
       " 'campaign',\n",
       " 'starts',\n",
       " 'Caldwell',\n",
       " 'expected',\n",
       " 'become',\n",
       " 'campaign',\n",
       " 'coordinator',\n",
       " 'Byrd',\n",
       " 'The',\n",
       " 'Georgia',\n",
       " 'Legislature',\n",
       " 'wind',\n",
       " '1961',\n",
       " 'session',\n",
       " 'Monday',\n",
       " 'head',\n",
       " 'home',\n",
       " '--',\n",
       " 'highway',\n",
       " 'bond',\n",
       " 'money',\n",
       " 'approved',\n",
       " 'follow',\n",
       " 'shortly',\n",
       " 'Before',\n",
       " 'adjournment',\n",
       " 'Monday',\n",
       " 'afternoon',\n",
       " 'Senate',\n",
       " 'expected',\n",
       " 'approve',\n",
       " 'study',\n",
       " 'number',\n",
       " 'legislators',\n",
       " 'allotted',\n",
       " 'rural',\n",
       " 'urban',\n",
       " 'areas',\n",
       " 'determine',\n",
       " 'adjustments',\n",
       " 'made',\n",
       " 'Gov.',\n",
       " 'Vandiver',\n",
       " 'expected',\n",
       " 'make',\n",
       " 'traditional',\n",
       " 'visit',\n",
       " 'chambers',\n",
       " 'work',\n",
       " 'toward',\n",
       " 'adjournment',\n",
       " 'Vandiver',\n",
       " 'likely',\n",
       " 'mention',\n",
       " '$100',\n",
       " 'million',\n",
       " 'highway',\n",
       " 'bond',\n",
       " 'issue',\n",
       " 'approved',\n",
       " 'earlier',\n",
       " 'session',\n",
       " 'first',\n",
       " 'priority',\n",
       " 'item',\n",
       " 'Construction',\n",
       " 'bonds',\n",
       " 'Meanwhile',\n",
       " 'learned',\n",
       " 'State',\n",
       " 'Highway',\n",
       " 'Department',\n",
       " 'near',\n",
       " 'ready',\n",
       " 'issue',\n",
       " 'first',\n",
       " '$30',\n",
       " 'million',\n",
       " 'worth',\n",
       " 'highway',\n",
       " 'reconstruction',\n",
       " 'bonds',\n",
       " 'The',\n",
       " 'bond',\n",
       " 'issue',\n",
       " 'go',\n",
       " 'state',\n",
       " 'courts',\n",
       " 'friendly',\n",
       " 'test',\n",
       " 'suit',\n",
       " 'test',\n",
       " 'validity',\n",
       " 'act',\n",
       " 'sales',\n",
       " 'begin',\n",
       " 'contracts',\n",
       " 'let',\n",
       " 'repair',\n",
       " 'work',\n",
       " \"Georgia's\",\n",
       " 'heavily',\n",
       " 'traveled',\n",
       " 'highways',\n",
       " 'A',\n",
       " 'Highway',\n",
       " 'Department',\n",
       " 'source',\n",
       " 'said',\n",
       " 'also',\n",
       " 'plan',\n",
       " 'issue',\n",
       " '$3',\n",
       " 'million',\n",
       " '$4',\n",
       " 'million',\n",
       " 'worth',\n",
       " 'Rural',\n",
       " 'Roads',\n",
       " 'Authority',\n",
       " 'bonds',\n",
       " 'rural',\n",
       " 'road',\n",
       " 'construction',\n",
       " 'work',\n",
       " 'A',\n",
       " 'revolving',\n",
       " 'fund',\n",
       " 'The',\n",
       " 'department',\n",
       " 'apparently',\n",
       " 'intends',\n",
       " 'make',\n",
       " 'Rural',\n",
       " 'Roads',\n",
       " 'Authority',\n",
       " 'revolving',\n",
       " 'fund',\n",
       " 'new',\n",
       " 'bonds',\n",
       " 'would',\n",
       " 'issued',\n",
       " 'every',\n",
       " 'time',\n",
       " 'portion',\n",
       " 'old',\n",
       " 'ones',\n",
       " 'paid',\n",
       " 'tax',\n",
       " 'authorities',\n",
       " 'Vandiver',\n",
       " 'opened',\n",
       " 'race',\n",
       " 'governor',\n",
       " '1958',\n",
       " 'battle',\n",
       " 'Legislature',\n",
       " 'issuance',\n",
       " '$50',\n",
       " 'million',\n",
       " 'worth',\n",
       " 'additional',\n",
       " 'rural',\n",
       " 'roads',\n",
       " 'bonds',\n",
       " 'proposed',\n",
       " 'Gov.',\n",
       " 'Marvin',\n",
       " 'Griffin',\n",
       " 'The',\n",
       " 'Highway',\n",
       " 'Department',\n",
       " 'source',\n",
       " 'told',\n",
       " 'The',\n",
       " 'Constitution',\n",
       " 'however',\n",
       " 'Vandiver',\n",
       " 'consulted',\n",
       " 'yet',\n",
       " 'plans',\n",
       " 'issue',\n",
       " 'new',\n",
       " 'rural',\n",
       " 'roads',\n",
       " 'bonds',\n",
       " 'Schley',\n",
       " 'County',\n",
       " 'Rep.',\n",
       " 'B.',\n",
       " 'D.',\n",
       " 'Pelham',\n",
       " 'offer',\n",
       " 'resolution',\n",
       " 'Monday',\n",
       " 'House',\n",
       " 'rescind',\n",
       " \"body's\",\n",
       " 'action',\n",
       " 'Friday',\n",
       " 'voting',\n",
       " '$10',\n",
       " 'per',\n",
       " 'day',\n",
       " 'increase',\n",
       " 'expense',\n",
       " 'allowances',\n",
       " 'Pelham',\n",
       " 'said',\n",
       " 'Sunday',\n",
       " 'night',\n",
       " 'research',\n",
       " 'done',\n",
       " 'whether',\n",
       " '``',\n",
       " 'quickie',\n",
       " \"''\",\n",
       " 'vote',\n",
       " 'increase',\n",
       " 'repealed',\n",
       " 'outright',\n",
       " 'whether',\n",
       " 'notice',\n",
       " 'would',\n",
       " 'first',\n",
       " 'given',\n",
       " 'reconsideration',\n",
       " 'action',\n",
       " 'would',\n",
       " 'sought',\n",
       " 'While',\n",
       " 'emphasizing',\n",
       " 'technical',\n",
       " 'details',\n",
       " 'fully',\n",
       " 'worked',\n",
       " 'Pelham',\n",
       " 'said',\n",
       " 'resolution',\n",
       " 'would',\n",
       " 'seek',\n",
       " 'set',\n",
       " 'aside',\n",
       " 'privilege',\n",
       " 'resolution',\n",
       " 'House',\n",
       " 'voted',\n",
       " '87-31',\n",
       " ...]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_docs_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bow = [dict.doc2bow(doc) for doc in brown_docs_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-15 17:58:15,748 : INFO : collecting document frequencies\n",
      "2018-06-15 17:58:15,750 : INFO : PROGRESS: processing document #0\n",
      "2018-06-15 17:58:15,872 : INFO : calculating IDF weights for 500 documents and 56056 features (354853 matrix non-zeros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 241 ms, sys: 8.39 ms, total: 249 ms\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_model = gensim.models.TfidfModel(corpus_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-15 17:59:23,258 : INFO : saving TfidfModel object under ./data/brown_tfidf.mm, separately None\n",
      "2018-06-15 17:59:23,514 : INFO : saved ./data/brown_tfidf.mm\n"
     ]
    }
   ],
   "source": [
    "tfidf_model.save('./data/brown_tfidf.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-15 18:07:11,141 : INFO : saving Dictionary object under ./data/brown_vocab, separately None\n",
      "2018-06-15 18:07:11,228 : INFO : saved ./data/brown_vocab\n"
     ]
    }
   ],
   "source": [
    "dict.save('./data/brown_vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Existing Lit on Hunt-Boas collaboration.They  note a wealth of sources by Ira Jacknis and Judith Berman about the Hunt-Boas partnerhips and correspondence, and they think this material makes possible a detailed examination of discursive practices and language ideology.  They disagree with treatment by others (Jacknis & Berman also?) in that this correspondence is treated as a fragment or special dimension of Boas work that esceaped some of the positivist trappings of Boass historical particularism.    They want to see these texts as continguous with Boass larger project and as providing revealing windows on the manner in which Boas sought to construct anthropology and to locate its practitioners--and the objects of their inquiries--within North American society and within a master narrative of modernity.'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Existing Lit on Hunt-Boas collaboration.They  note a wealth of sources by Ira Jacknis and Judith Berman about the Hunt-Boas partnerhips and correspondence, and they think this material makes possible a detailed examination of discursive practices and language ideology.  They disagree with treatment by others (Jacknis & Berman also?) in that this correspondence is treated as a fragment or special dimension of Boas work that esceaped some of the positivist trappings of Boass historical particularism.    They want to see these texts as continguous with Boass larger project and as providing revealing windows on the manner in which Boas sought to construct anthropology and to locate its practitioners--and the objects of their inquiries--within North American society and within a master narrative of modernity.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collaboration.They',\n",
       " 'wealth',\n",
       " 'correspondence',\n",
       " 'material',\n",
       " 'examination',\n",
       " 'language',\n",
       " 'ideology',\n",
       " 'treatment',\n",
       " 'correspondence',\n",
       " 'fragment',\n",
       " 'dimension',\n",
       " 'work',\n",
       " 'particularism',\n",
       " 'project',\n",
       " 'manner',\n",
       " 'anthropology',\n",
       " 'society',\n",
       " 'master',\n",
       " 'narrative',\n",
       " 'modernity']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myfuncs import get_pairs, get_unigrams\n",
    "\n",
    "# def get_keywords(text, vocab, model):\n",
    "#     tokens = [\" \".join(x) for x in get_pairs(text)]\n",
    "#     bow = vocab.doc2bow(tokens)\n",
    "#     scores = model[bow]\n",
    "#     sorted_list = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "#     for word_id, score in sorted_list:\n",
    "#         yield vocab[word_id], score\n",
    "        \n",
    "tokens = [x for x in get_unigrams(text)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(45, 1),\n",
       " (320, 1),\n",
       " (1287, 1),\n",
       " (4241, 1),\n",
       " (4417, 1),\n",
       " (5379, 1),\n",
       " (10486, 1),\n",
       " (11891, 1),\n",
       " (12064, 2),\n",
       " (12381, 1),\n",
       " (12609, 1),\n",
       " (13523, 1),\n",
       " (19500, 1),\n",
       " (22823, 1),\n",
       " (25187, 1),\n",
       " (29407, 1),\n",
       " (34722, 1)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = dict.doc2bow(tokens)\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(45, 0.11221409628729304),\n",
       " (320, 0.033763889180712034),\n",
       " (1287, 0.15112820591623072),\n",
       " (4241, 0.16440472035346593),\n",
       " (4417, 0.12856709560952354),\n",
       " (5379, 0.16154080113553265),\n",
       " (10486, 0.11725312252788321),\n",
       " (11891, 0.14206319169247905),\n",
       " (12064, 0.4664321012468349),\n",
       " (12381, 0.2560464751899652),\n",
       " (12609, 0.2677663680840693),\n",
       " (13523, 0.24600705254486052),\n",
       " (19500, 0.2560464751899652),\n",
       " (22823, 0.3589192270150077),\n",
       " (25187, 0.22240141259303622),\n",
       " (29407, 0.31029060034962225),\n",
       " (34722, 0.3230816022710653)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = tfidf_model[bow]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correspondence 0.4664321012468349\n",
      "modernity 0.3589192270150077\n",
      "fragment 0.3230816022710653\n",
      "anthropology 0.31029060034962225\n",
      "ideology 0.2677663680840693\n",
      "dimension 0.2560464751899652\n",
      "narrative 0.2560464751899652\n",
      "wealth 0.24600705254486052\n",
      "examination 0.22240141259303622\n",
      "master 0.16440472035346593\n",
      "treatment 0.16154080113553265\n",
      "project 0.15112820591623072\n",
      "language 0.14206319169247905\n",
      "society 0.12856709560952354\n",
      "material 0.11725312252788321\n",
      "manner 0.11221409628729304\n",
      "work 0.033763889180712034\n"
     ]
    }
   ],
   "source": [
    "sorted_list = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "for word_id, score in sorted_list:\n",
    "    print(dict[word_id], score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
